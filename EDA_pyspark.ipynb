{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d19805a",
   "metadata": {},
   "source": [
    "# Set up packages and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d37f948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StringType, ArrayType\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import regex\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# Enable Arrow-based columnar data transfers\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65ba08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "transactions = spark.read.options(    \n",
    "        header=True,  \n",
    "        inferSchema=True\n",
    "    ).csv(\n",
    "        os.path.join(DATA_FOLDER, 'sales_train.csv'), \n",
    "    )\n",
    "\n",
    "items = spark.read.options(    \n",
    "        header=True,  \n",
    "        inferSchema=True\n",
    "    ).csv(\n",
    "        os.path.join(DATA_FOLDER, 'items.csv'), \n",
    "    )\n",
    "\n",
    "item_categories = spark.read.options(    \n",
    "        header=True,  \n",
    "        inferSchema=True\n",
    "    ).csv(\n",
    "        os.path.join(DATA_FOLDER, 'item_categories.csv'), \n",
    "    )\n",
    "\n",
    "shops = spark.read.options(    \n",
    "        header=True,  \n",
    "        inferSchema=True\n",
    "    ).csv(\n",
    "        os.path.join(DATA_FOLDER, 'shops.csv'), \n",
    "    )\n",
    "\n",
    "test = spark.read.options(    \n",
    "        header=True,  \n",
    "        inferSchema=True\n",
    "    ).csv(\n",
    "        os.path.join(DATA_FOLDER, 'test.csv'), \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa264c1e",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf45bb",
   "metadata": {},
   "source": [
    "## Look at dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc5a71",
   "metadata": {},
   "source": [
    "Print the top 10 rows and the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05b1e9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 2935849\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|      date|date_block_num|shop_id|item_id|item_price|item_cnt_day|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "|02.01.2013|             0|     59|  22154|     999.0|         1.0|\n",
      "|03.01.2013|             0|     25|   2552|     899.0|         1.0|\n",
      "|05.01.2013|             0|     25|   2552|     899.0|        -1.0|\n",
      "|06.01.2013|             0|     25|   2554|   1709.05|         1.0|\n",
      "|15.01.2013|             0|     25|   2555|    1099.0|         1.0|\n",
      "|10.01.2013|             0|     25|   2564|     349.0|         1.0|\n",
      "|02.01.2013|             0|     25|   2565|     549.0|         1.0|\n",
      "|04.01.2013|             0|     25|   2572|     239.0|         1.0|\n",
      "|11.01.2013|             0|     25|   2572|     299.0|         1.0|\n",
      "|03.01.2013|             0|     25|   2573|     299.0|         3.0|\n",
      "+----------+--------------+-------+-------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Total number of rows: 22170\n",
      "+--------------------+-------+----------------+\n",
      "|           item_name|item_id|item_category_id|\n",
      "+--------------------+-------+----------------+\n",
      "|! ВО ВЛАСТИ НАВАЖ...|      0|              40|\n",
      "|!ABBYY FineReader...|      1|              76|\n",
      "|***В ЛУЧАХ СЛАВЫ ...|      2|              40|\n",
      "|***ГОЛУБАЯ ВОЛНА ...|      3|              40|\n",
      "|***КОРОБКА (СТЕКЛ...|      4|              40|\n",
      "|***НОВЫЕ АМЕРИКАН...|      5|              40|\n",
      "|***УДАР ПО ВОРОТА...|      6|              40|\n",
      "|***УДАР ПО ВОРОТА...|      7|              40|\n",
      "|***ЧАЙ С МУССОЛИН...|      8|              40|\n",
      "|***ШУГАРЛЭНДСКИЙ ...|      9|              40|\n",
      "+--------------------+-------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Total number of rows: 84\n",
      "+--------------------+----------------+\n",
      "|  item_category_name|item_category_id|\n",
      "+--------------------+----------------+\n",
      "|PC - Гарнитуры/На...|               0|\n",
      "|    Аксессуары - PS2|               1|\n",
      "|    Аксессуары - PS3|               2|\n",
      "|    Аксессуары - PS4|               3|\n",
      "|    Аксессуары - PSP|               4|\n",
      "| Аксессуары - PSVita|               5|\n",
      "|Аксессуары - XBOX...|               6|\n",
      "|Аксессуары - XBOX...|               7|\n",
      "|      Билеты (Цифра)|               8|\n",
      "|     Доставка товара|               9|\n",
      "+--------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Total number of rows: 60\n",
      "+--------------------+-------+\n",
      "|           shop_name|shop_id|\n",
      "+--------------------+-------+\n",
      "|!Якутск Орджоники...|      0|\n",
      "|\"!Якутск ТЦ \"\"Цен...|      1|\n",
      "|\"Адыгея ТЦ \"\"Мега\"\"\"|      2|\n",
      "|\"Балашиха ТРК \"\"О...|      3|\n",
      "|\"Волжский ТЦ \"\"Во...|      4|\n",
      "|\"Вологда ТРЦ \"\"Ма...|      5|\n",
      "|Воронеж (Плеханов...|      6|\n",
      "|\"Воронеж ТРЦ \"\"Ма...|      7|\n",
      "|\"Воронеж ТРЦ Сити...|      8|\n",
      "|   Выездная Торговля|      9|\n",
      "+--------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Total number of rows: 214200\n",
      "+---+-------+-------+\n",
      "| ID|shop_id|item_id|\n",
      "+---+-------+-------+\n",
      "|  0|      5|   5037|\n",
      "|  1|      5|   5320|\n",
      "|  2|      5|   5233|\n",
      "|  3|      5|   5232|\n",
      "|  4|      5|   5268|\n",
      "|  5|      5|   5039|\n",
      "|  6|      5|   5041|\n",
      "|  7|      5|   5046|\n",
      "|  8|      5|   5319|\n",
      "|  9|      5|   5003|\n",
      "+---+-------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Total number of rows: {}'.format(transactions.count()))\n",
    "transactions.show(10)\n",
    "\n",
    "print('Total number of rows: {}'.format(items.count()))\n",
    "items.show(10)\n",
    "\n",
    "print('Total number of rows: {}'.format(item_categories.count()))\n",
    "item_categories.show(10)\n",
    "\n",
    "print('Total number of rows: {}'.format(shops.count()))\n",
    "shops.show(10)\n",
    "\n",
    "print('Total number of rows: {}'.format(test.count()))\n",
    "test.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd54e709",
   "metadata": {},
   "source": [
    "We see that in the training dataset, there are 2935849 transactions, 22170 items, 84 item categories and 60 shops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d2a9d9",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc06d042",
   "metadata": {},
   "source": [
    "## Create the base training dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9a4721",
   "metadata": {},
   "source": [
    "For every month we create a grid from all shops/items combinations from that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f17e37ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions.createOrReplaceTempView('transactions')\n",
    "\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "grid = []\n",
    "date_block_nums = transactions.select('date_block_num').distinct().toPandas()['date_block_num'].unique()\n",
    "for block_num in date_block_nums:\n",
    "    cur_shops = spark.sql(\"\"\"SELECT DISTINCT shop_id \n",
    "                                FROM transactions\n",
    "                                WHERE date_block_num = {block_num}\"\"\".format(block_num = block_num)\n",
    "                            ).toPandas()['shop_id'].unique()\n",
    "    cur_items = spark.sql(\"\"\"SELECT DISTINCT item_id \n",
    "                                FROM transactions\n",
    "                                WHERE date_block_num = {block_num}\"\"\".format(block_num = block_num)\n",
    "                            ).toPandas()['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols, dtype=np.int32)\n",
    "train = spark.createDataFrame(grid)\n",
    "\n",
    "del grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e689ee25",
   "metadata": {},
   "source": [
    "## Aggregate sales and revenue by month, item id and shop id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3768f8",
   "metadata": {},
   "source": [
    "Add item revenue as a feature to the transactions dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3398eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions.withColumn('item_revenue', transactions.item_cnt_day * transactions.item_price)\n",
    "\n",
    "transactions.createOrReplaceTempView('transactions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70911b0",
   "metadata": {},
   "source": [
    "Aggregate sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4e5eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = transactions.select('item_cnt_day', *index_cols).groupby(index_cols) \\\n",
    "        .sum('item_cnt_day').withColumnRenamed('sum(item_cnt_day)', 'target')\n",
    "# Join it to the grid\n",
    "train = train.join(gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = transactions.select('item_cnt_day', *index_cols).groupby('shop_id', 'date_block_num') \\\n",
    "        .sum('item_cnt_day').withColumnRenamed('sum(item_cnt_day)', 'target_shop')\n",
    "# Join it to the grid\n",
    "train = train.join(gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = transactions.select('item_cnt_day', *index_cols).groupby('item_id', 'date_block_num') \\\n",
    "        .sum('item_cnt_day').withColumnRenamed('sum(item_cnt_day)', 'target_item')\n",
    "# Join it to the grid\n",
    "train = train.join(gb, how='left', on=['item_id', 'date_block_num']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc31286",
   "metadata": {},
   "source": [
    "Aggregate revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8146e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = transactions.select('item_revenue', *index_cols).groupby(index_cols) \\\n",
    "        .sum('item_revenue').withColumnRenamed('sum(item_revenue)', 'revenue')\n",
    "# Join it to the grid\n",
    "train = train.join(gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = transactions.select('item_revenue', *index_cols).groupby('shop_id', 'date_block_num') \\\n",
    "        .sum('item_revenue').withColumnRenamed('sum(item_revenue)', 'revenue_shop')\n",
    "# Join it to the grid\n",
    "train = train.join(gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = transactions.select('item_revenue', *index_cols).groupby('item_id', 'date_block_num') \\\n",
    "        .sum('item_revenue').withColumnRenamed('sum(item_revenue)', 'revenue_item')\n",
    "# Join it to the grid\n",
    "train = train.join(gb, how='left', on=['item_id', 'date_block_num']).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e18835",
   "metadata": {},
   "source": [
    "## Normalize numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6e4c2b",
   "metadata": {},
   "source": [
    "Min-max scale target_shops and target_items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cf9387d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_shops\n",
    "stats = train.select(F.max(train.target_shop).alias('max'),\n",
    "                  F.min(train.target_shop).alias('min')).collect()\n",
    "\n",
    "mx = stats[0]['max']\n",
    "mn = stats[0]['min']\n",
    "\n",
    "train = train.withColumn('normalized_target_shop', (train.target_shop - mn) / (mx - mn))\n",
    "\n",
    "# target_items\n",
    "stats = train.select(F.max(train.target_item).alias('max'),\n",
    "                  F.min(train.target_item).alias('min')).collect()\n",
    "\n",
    "mx = stats[0]['max']\n",
    "mn = stats[0]['min']\n",
    "\n",
    "train = train.withColumn('normalized_target_item', (train.target_item - mn) / (mx - mn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cd77c6",
   "metadata": {},
   "source": [
    "Do the same for revenue, revenue_shops and revenue_items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a29b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revenue\n",
    "stats = train.select(F.max(train.revenue).alias('max'),\n",
    "                  F.min(train.revenue).alias('min')).collect()\n",
    "\n",
    "mx = stats[0]['max']\n",
    "mn = stats[0]['min']\n",
    "\n",
    "train = train.withColumn('normalized_revenue', (train.revenue - mn) / (mx - mn))\n",
    "\n",
    "# revenue_shops\n",
    "stats = train.select(F.max(train.revenue_shop).alias('max'),\n",
    "                  F.min(train.revenue_shop).alias('min')).collect()\n",
    "\n",
    "mx = stats[0]['max']\n",
    "mn = stats[0]['min']\n",
    "\n",
    "train = train.withColumn('normalized_revenue_shop', (train.revenue_shop - mn) / (mx - mn))\n",
    "\n",
    "# revenue_items\n",
    "stats = train.select(F.max(train.revenue_item).alias('max'),\n",
    "                  F.min(train.revenue_item).alias('min')).collect()\n",
    "\n",
    "mx = stats[0]['max']\n",
    "mn = stats[0]['min']\n",
    "\n",
    "train = train.withColumn('normalized_revenue_item', (train.revenue_item - mn) / (mx - mn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3b94d",
   "metadata": {},
   "source": [
    "## Add values from previous months as features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766f4088",
   "metadata": {},
   "source": [
    "Create new features using lags from [1, 2, 3, 4, 5, 12] months ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e724e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = [col for col in train.columns if col not in index_cols]\n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "for month_shift in shift_range:\n",
    "    train_shift = train.select(*(index_cols + cols_to_rename))\n",
    "    \n",
    "    train_shift.withColumn('date_block_num', train_shift.date_block_num + 1)\n",
    "    \n",
    "    for col in cols_to_rename:\n",
    "        train_shift = train_shift.withColumnRenamed(col, '{}_lag_{}'.format(col, month_shift))\n",
    "        \n",
    "    train = train.join(train_shift, on=index_cols, how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae46581",
   "metadata": {},
   "source": [
    "## Mean encode categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b337b25",
   "metadata": {},
   "source": [
    "Add item_category_id to the train dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e98da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(items, how='left', on='item_id').select(train.columns + ['item_category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3e7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['shop_id', 'item_id', 'item_category_id']\n",
    "\n",
    "num_splits = 5\n",
    "\n",
    "for name in labels:\n",
    "    global_mean = train.select(F.avg(name)).collect()[0][0]\n",
    "    tr = train.select(name, 'target').randomSplit(num_splits * [1.], seed=27)\n",
    "\n",
    "    # make a dataframe consisting of all rows except the rows to encode, then take the target mean\n",
    "    for k_enc in range(num_splits):\n",
    "        tr_mean = None\n",
    "        for k_mean in range(num_splits):\n",
    "            if k_mean != k_enc:\n",
    "                if tr_mean is None:\n",
    "                    tr_mean = tr[k_mean].select(name, 'target')\n",
    "                else:\n",
    "                    tr_mean = tr_mean.union(tr[k_mean].select(name, 'target'))\n",
    "        avg = tr_mean.groupBy(name).avg('target').withColumnRenamed('avg(target)', name + '_enc')\n",
    "        tr[k_enc] = tr[k_enc].join(avg, how='left', on=name).fillna(global_mean)\n",
    "\n",
    "    # make a dataframe consisting of all mean encodings\n",
    "    tr_tot = None\n",
    "    for k in range(num_splits):\n",
    "        if tr_tot is None:\n",
    "            tr_tot = tr[k].select(name, name + '_enc')\n",
    "        else:\n",
    "            tr_tot = tr_tot.union(tr[k].select(name, name + '_enc'))\n",
    "\n",
    "    # join onto the train dataframe\n",
    "    train = train.join(tr_tot, how='left', on=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597b7a63",
   "metadata": {},
   "source": [
    "## Extract text-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20b9dd",
   "metadata": {},
   "source": [
    "### Stem the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268a874",
   "metadata": {},
   "source": [
    "Define a stemmer that can handle both Russian and English text using nltk's Snowball Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d8fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stemmer = SnowballStemmer('english')\n",
    "ru_stemmer = SnowballStemmer('russian')\n",
    "\n",
    "cyr_regex = regex.compile('\\p{Cyrillic}+', regex.UNICODE)\n",
    "lat_regex = regex.compile('\\p{Latin}+', regex.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08f7ef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" Removes punctuation from string, unwanted unicode characters, and numbers. Returns in lowercase.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to clean.\n",
    "    \n",
    "    Returns:\n",
    "        The cleaned text after filtered by the regex expression and made lowercase.\n",
    "    \n",
    "    For more information on the unicode categories used in the regex expression see here:\n",
    "    https://www.regular-expressions.info/unicode.html#category\n",
    "    \n",
    "    >>> clean_text(\"!$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ Can't, - Trademark™ ...「（Punctuation）」42.32 ?\")\n",
    "    cant trademark punctuation\n",
    "    \n",
    "    \"\"\"\n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # remove apostrophes \n",
    "    text = text.replace(\"'\", \"\")\n",
    "    \n",
    "    # Define regex unicode Categories and strip from string\n",
    "    remove = regex.compile('[\\p{C}|\\p{M}|\\p{P}|\\p{S}|\\p{Z}|\\p{N}]+', regex.UNICODE)\n",
    "    text = remove.sub(\" \", text).strip()\n",
    "    \n",
    "    # make lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def stemmer(text):\n",
    "    \"\"\"Identify the words written in Cyrillic and Latin characters in a string,\n",
    "    and apply a Russian or English stemmer, respectively.\n",
    "    \n",
    "    Args:\n",
    "        text(str): The string whose Cyrillic and Latin text will be stemmed.\n",
    "    \n",
    "    Returns:\n",
    "        A stemmed version of the text.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return []\n",
    "    \n",
    "    text = clean_text(text)\n",
    "\n",
    "    words = re.split('\\s', text)\n",
    "    stemmed_word_list = []\n",
    "    for word in words:\n",
    "        ru = regex.search(cyr_regex, word)\n",
    "        en = regex.search(lat_regex, word)\n",
    "        if ru:\n",
    "            stemmed_word = ru_stemmer.stem(word)\n",
    "        elif en:\n",
    "            stemmed_word = en_stemmer.stem(word)\n",
    "        else:\n",
    "            stemmed_word = word\n",
    "        stemmed_word_list.append(stemmed_word)\n",
    "    \n",
    "    return stemmed_word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8b8a5",
   "metadata": {},
   "source": [
    "Demonstrate function on sample text from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "842b7396",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-83a78af60901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'(Кино) - Blu-Ray'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-ccae2e4eedab>\u001b[0m in \u001b[0;36mstemmer\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-ccae2e4eedab>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# remove URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"http\\S+\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;31m# remove apostrophes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "text = '(Кино) - Blu-Ray'\n",
    "\n",
    "stemmer(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc42fc64",
   "metadata": {},
   "source": [
    "Apply stemmer to columns containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706ab421",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_stemmer = F.udf(stemmer, ArrayType(StringType(), True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116bb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = items.withColumn('stemmed_item_name', udf_stemmer(items.item_name))\n",
    "item_categories = item_categories.withColumn('stemmed_item_category_name', udf_stemmer(item_categories.item_category_name))\n",
    "shops = shops.withColumn('stemmed_shop_name', udf_stemmer(shops.shop_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa7b75c",
   "metadata": {},
   "source": [
    "### Vectorize using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd23715d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "idf = IDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe811ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.setInputCol('stemmed_item_name')\n",
    "cv.setOutputCol('bow_item_name')\n",
    "cvmodel = cv.fit(items)\n",
    "items = cvmodel.transform(items)\n",
    "\n",
    "idf.setInputCol('bow_item_name')\n",
    "idf.setOutputCol('tfidf_item_name')\n",
    "idfmodel = idf.fit(items)\n",
    "items = idfmodel.transform(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ee83e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.setInputCol('stemmed_item_category_name')\n",
    "cv.setOutputCol('bow_item_category_name')\n",
    "cvmodel = cv.fit(item_categories)\n",
    "item_categories = cvmodel.transform(item_categories)\n",
    "\n",
    "idf.setInputCol('bow_item_category_name')\n",
    "idf.setOutputCol('tfidf_item_category_name')\n",
    "idfmodel = idf.fit(item_categories)\n",
    "item_categories = idfmodel.transform(item_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74002880",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.setInputCol('stemmed_shop_name')\n",
    "cv.setOutputCol('bow_shop_name')\n",
    "cvmodel = cv.fit(shops)\n",
    "shops = cvmodel.transform(shops)\n",
    "\n",
    "idf.setInputCol('bow_shop_name')\n",
    "idf.setOutputCol('tfidf_shop_name')\n",
    "idfmodel = idf.fit(shops)\n",
    "shops = idfmodel.transform(shops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6257c808",
   "metadata": {},
   "source": [
    "### Join TFIDF-encoded item/item category/shop names onto the training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c488accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView('train')\n",
    "items.createOrReplaceTempView('items')\n",
    "\n",
    "train = spark.sql(('SELECT train.*, items.item_category_id, items.tfidf_item_name '\n",
    "                  ' FROM train '\n",
    "                  ' LEFT JOIN items '\n",
    "                  '  ON train.item_id = items.item_id '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView('train')\n",
    "item_categories.createOrReplaceTempView('item_categories')\n",
    "\n",
    "train = spark.sql(('SELECT train.*, item_categories.tfidf_item_category_name '\n",
    "                  ' FROM train '\n",
    "                  ' LEFT JOIN item_categories '\n",
    "                  '  ON train.item_category_id = item_categories.item_category_id '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce92c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.createOrReplaceTempView('train')\n",
    "shops.createOrReplaceTempView('shops')\n",
    "\n",
    "train = spark.sql(('SELECT train.*, shops.tfidf_shop_name '\n",
    "                  ' FROM train '\n",
    "                  ' LEFT JOIN shops '\n",
    "                  '  ON train.shop_id = shops.shop_id '))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c655a22",
   "metadata": {},
   "source": [
    "## Display the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d552e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae90d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
