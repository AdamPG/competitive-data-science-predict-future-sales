{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f83359",
   "metadata": {},
   "source": [
    "# Import packages and load dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d912a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import regex\n",
    "from itertools import product\n",
    "import gc\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852ef838",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "sales = pd.read_csv(os.path.join(DATA_FOLDER, 'sales_train.csv'))\n",
    "shops = pd.read_csv(os.path.join(DATA_FOLDER, 'shops.csv'))\n",
    "items = pd.read_csv(os.path.join(DATA_FOLDER, 'items.csv'))\n",
    "item_cats = pd.read_csv(os.path.join(DATA_FOLDER, 'item_categories.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099c2592",
   "metadata": {},
   "source": [
    "# Define some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26728747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downcast_dtypes(df):\n",
    "    '''\n",
    "        Changes column types in the dataframe: \n",
    "                \n",
    "                `float64` type to `float32`\n",
    "                `int64`   type to `int32`\n",
    "    '''\n",
    "    \n",
    "    # Select columns to downcast\n",
    "    float_cols = [c for c in df if df[c].dtype == \"float64\"]\n",
    "    int_cols =   [c for c in df if df[c].dtype == \"int64\"]\n",
    "    \n",
    "    # Downcast\n",
    "    df[float_cols] = df[float_cols].astype(np.float32)\n",
    "    df[int_cols]   = df[int_cols].astype(np.int32)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc135515",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffc0f01",
   "metadata": {},
   "source": [
    "## Create the base training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92bdcca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"grid\" with columns\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales.loc[sales['date_block_num'] == block_num, 'shop_id'].unique()\n",
    "    cur_items = sales.loc[sales['date_block_num'] == block_num, 'item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "# Turn the grid into a dataframe\n",
    "all_data = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8a4663",
   "metadata": {},
   "source": [
    "## Aggregate sales and revenue by month, item id and shop id."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb89e30",
   "metadata": {},
   "source": [
    "Add item revenue as a feature to the transactions dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec30e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales['item_revenue'] = sales.item_cnt_day * sales.item_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bab6fcd",
   "metadata": {},
   "source": [
    "Aggregate sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cb7b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_cnt_day':'sum'})\n",
    "# Fix column names\n",
    "gb.columns = ['target' if col == 'item_cnt_day' else col for col in gb.columns.values]\n",
    "# Join it to the grid\n",
    "all_data = pd.merge(all_data, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "gb.columns = ['target_shop' if col == 'item_cnt_day' else col for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_cnt_day':'sum'})\n",
    "gb.columns = ['target_item' if col == 'item_cnt_day' else col for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "# del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97752e10",
   "metadata": {},
   "source": [
    "Aggregate revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45007a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby data to get shop-item-month aggregates\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'item_revenue':'sum'})\n",
    "# Fix column names\n",
    "gb.columns = ['revenue' if col == 'item_revenue' else col for col in gb.columns.values]\n",
    "# Join it to the grid\n",
    "all_data = pd.merge(all_data, gb, how='left', on=index_cols).fillna(0)\n",
    "\n",
    "# Same as above but with shop-month aggregates\n",
    "gb = sales.groupby(['shop_id', 'date_block_num'],as_index=False).agg({'item_revenue':'sum'})\n",
    "gb.columns = ['revenue_shop' if col == 'item_revenue' else col for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['shop_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Same as above but with item-month aggregates\n",
    "gb = sales.groupby(['item_id', 'date_block_num'],as_index=False).agg({'item_revenue':'sum'})\n",
    "gb.columns = ['revenue_item' if col == 'item_revenue' else col for col in gb.columns.values]\n",
    "all_data = pd.merge(all_data, gb, how='left', on=['item_id', 'date_block_num']).fillna(0)\n",
    "\n",
    "# Downcast dtypes from 64 to 32 bit to save memory\n",
    "all_data = downcast_dtypes(all_data)\n",
    "# del grid, gb \n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f2d7a",
   "metadata": {},
   "source": [
    "## Normalize numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36eec58",
   "metadata": {},
   "source": [
    "We choose to normalize using a min-max scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec10f89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of numerical columns to normalize\n",
    "num_cols = [col for col in all_data.columns if col.startswith('target') or col.startswith('revenue')]\n",
    "\n",
    "# Normalize the columns\n",
    "for col in num_cols:\n",
    "    col_min = all_data[col].min()\n",
    "    col_max = all_data[col].max()\n",
    "    all_data[col + '_normalized'] = (all_data[col] - col_min) / (col_max - col_min)\n",
    "    \n",
    "# Drop unnormalized columns except for 'target'\n",
    "cols_to_drop = [col for col in num_cols if col != 'target']\n",
    "all_data.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c684a4",
   "metadata": {},
   "source": [
    "## Add values from previous months as features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7edf635",
   "metadata": {},
   "source": [
    "Create new features using lags from [1, 2, 3, 4, 5, 12] months ago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9be62b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3291d89ba349849c274ba63821aa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of columns that we will use to create lags\n",
    "cols_to_rename = list(all_data.columns.difference(index_cols + ['target']))\n",
    "\n",
    "shift_range = [1, 2, 3, 4, 5, 12]\n",
    "\n",
    "for month_shift in tqdm_notebook(shift_range):\n",
    "    train_shift = all_data[index_cols + cols_to_rename].copy()\n",
    "    \n",
    "    train_shift['date_block_num'] = train_shift['date_block_num'] + month_shift\n",
    "    \n",
    "    foo = lambda x: '{}_lag_{}'.format(x, month_shift) if x in cols_to_rename else x\n",
    "    train_shift = train_shift.rename(columns=foo)\n",
    "\n",
    "    all_data = pd.merge(all_data, train_shift, on=index_cols, how='left').fillna(0)\n",
    "\n",
    "del train_shift\n",
    "\n",
    "# Don't use old data from year 2013\n",
    "all_data = all_data[all_data['date_block_num'] >= 12] \n",
    "\n",
    "# List of all lagged features\n",
    "fit_cols = [col for col in all_data.columns if col[-1] in [str(item) for item in shift_range]] \n",
    "# We will drop these at fitting stage\n",
    "to_drop_cols = list(set(list(all_data.columns)) - (set(fit_cols)|set(index_cols))) + ['date_block_num'] \n",
    "\n",
    "# Category for each item\n",
    "item_category_mapping = items[['item_id','item_category_id']].drop_duplicates()\n",
    "\n",
    "all_data = pd.merge(all_data, item_category_mapping, how='left', on='item_id')\n",
    "all_data = downcast_dtypes(all_data)\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12354a",
   "metadata": {},
   "source": [
    "Normalized targets and revenues without a lag are not available as features in the test dataset, so we drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33d0136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['target', 'target_shop', 'target_item', 'revenue', 'revenue_shop', 'revenue_item']\n",
    "cols_to_drop = [col + '_normalized' for col in cols_to_drop]\n",
    "all_data.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549e253",
   "metadata": {},
   "source": [
    "## Extract text-based features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554e97b0",
   "metadata": {},
   "source": [
    "### Stem the text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27571ef",
   "metadata": {},
   "source": [
    "Define a stemmer that can handle both Russian and English text using nltk's Snowball Stemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eabdba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "ru_stemmer = SnowballStemmer('russian', ignore_stopwords=True)\n",
    "\n",
    "cyr_regex = regex.compile('\\p{Cyrillic}+', regex.UNICODE)\n",
    "lat_regex = regex.compile('\\p{Latin}+', regex.UNICODE)\n",
    "\n",
    "en_stopwords = stopwords.words(\"english\")\n",
    "ru_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b693b63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\" Removes punctuation from string, unwanted unicode characters, and numbers. Returns in lowercase.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to clean.\n",
    "    \n",
    "    Returns:\n",
    "        The cleaned text after filtered by the regex expression and made lowercase.\n",
    "    \n",
    "    For more information on the unicode categories used in the regex expression see here:\n",
    "    https://www.regular-expressions.info/unicode.html#category\n",
    "    \n",
    "    >>> clean_text(\"!$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ Can't, - Trademark™ ...「（Punctuation）」42.32 ?\")\n",
    "    cant trademark punctuation\n",
    "    \n",
    "    \"\"\"\n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # remove apostrophes \n",
    "    text = text.replace(\"'\", \"\")\n",
    "    \n",
    "    # Define regex unicode Categories and strip from string\n",
    "    remove = regex.compile('[\\p{C}|\\p{M}|\\p{P}|\\p{S}|\\p{Z}|\\p{N}]+', regex.UNICODE)\n",
    "    text = remove.sub(\" \", text).strip()\n",
    "    \n",
    "    # make lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d3472a",
   "metadata": {},
   "source": [
    "Apply clean_text to stopwords to make removal easier in the preprocess_text function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aca83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_en_stopwords = [clean_text(word) for word in en_stopwords]\n",
    "cleaned_ru_stopwords = [clean_text(word) for word in ru_stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d448eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Identify the words written in Cyrillic and Latin characters in a string,\n",
    "    remove stop words and apply a Russian or English stemmer, respectively.\n",
    "    \n",
    "    Args:\n",
    "        text(str): The string whose Cyrillic and Latin text will be stemmed.\n",
    "    \n",
    "    Returns:\n",
    "        A stemmed version of the text.\n",
    "    \"\"\"\n",
    "    if text is None:\n",
    "        return []\n",
    "    \n",
    "    text = clean_text(text)\n",
    "\n",
    "    words = re.split('\\s', text)\n",
    "    stemmed_sentence = ''\n",
    "    for word in words:\n",
    "        ru = regex.search(cyr_regex, word)\n",
    "        en = regex.search(lat_regex, word)\n",
    "        if ru:\n",
    "            # drop stopwords from the sentence\n",
    "            if word in cleaned_ru_stopwords:\n",
    "                continue\n",
    "            stemmed_word = ru_stemmer.stem(word)\n",
    "        elif en:\n",
    "            # drop stopwords from the sentence\n",
    "            if word in cleaned_en_stopwords:\n",
    "                continue\n",
    "            stemmed_word = en_stemmer.stem(word)\n",
    "        else:\n",
    "            stemmed_word = word\n",
    "        stemmed_sentence = stemmed_sentence + ' ' + stemmed_word\n",
    "    \n",
    "    return stemmed_sentence[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955a7643",
   "metadata": {},
   "source": [
    "Demonstrate function on sample text from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc735c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'кин blu ray'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = '(Кино) - Blu-Ray'\n",
    "\n",
    "preprocess_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3148d2",
   "metadata": {},
   "source": [
    "Apply stemmer to columns containing text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7101056",
   "metadata": {},
   "outputs": [],
   "source": [
    "shops['preprocessed_shop_name'] = shops['shop_name'].map(preprocess_text)\n",
    "items['preprocessed_item_name'] = items['item_name'].map(preprocess_text)\n",
    "item_cats['preprocessed_item_category_name'] = item_cats['item_category_name'].map(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c229c",
   "metadata": {},
   "source": [
    "### Vectorize using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c98f245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45db070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_shop_names = vectorizer.fit_transform(shops['preprocessed_shop_name'].values)\n",
    "tfidf_shop_names = pd.DataFrame.sparse.from_spmatrix(tfidf_shop_names)\n",
    "tfidf_shop_names.columns = ['vect_shop_name_' + str(col) for col in tfidf_shop_names.columns]\n",
    "shops = shops.join(tfidf_shop_names)\n",
    "\n",
    "tfidf_item_names = vectorizer.fit_transform(items['preprocessed_item_name'].values)\n",
    "tfidf_item_names = pd.DataFrame.sparse.from_spmatrix(tfidf_item_names)\n",
    "tfidf_item_names.columns = ['vect_item_name_' + str(col) for col in tfidf_item_names.columns]\n",
    "items = items.join(tfidf_item_names)\n",
    "\n",
    "tfidf_item_cat_names = vectorizer.fit_transform(item_cats['preprocessed_item_category_name'].values)\n",
    "tfidf_item_cat_names = pd.DataFrame.sparse.from_spmatrix(tfidf_item_cat_names)\n",
    "tfidf_item_cat_names.columns = ['vect_item_category_name_' + str(col) for col in tfidf_item_cat_names.columns]\n",
    "item_cats = item_cats.join(tfidf_item_cat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463cac91",
   "metadata": {},
   "source": [
    "### Join TFIDF-encoded item/item category/shop names onto the training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5409b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect_shop_cols = [col for col in shops.columns if col.startswith('vect')]\n",
    "# all_data = all_data.join(shops[vect_shop_cols], on='shop_id', how='left')\n",
    "\n",
    "# vect_item_cols = [col for col in items.columns if col.startswith('vect')]\n",
    "# all_data = all_data.join(items[vect_item_cols], on='item_id', how='left')\n",
    "\n",
    "# vect_item_cat_cols = [col for col in item_cats.columns if col.startswith('vect')]\n",
    "# all_data = all_data.join(item_cats[vect_item_cat_cols], on='item_category_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb56e8b",
   "metadata": {},
   "source": [
    "## Mean encode categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd266d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "cat_cols = ['shop_id', 'item_id', 'item_category_id']\n",
    "\n",
    "for col in cat_cols:\n",
    "    all_data[col + '_enc'] = np.nan\n",
    "\n",
    "    for train_index, val_index in kf.split(all_data):\n",
    "        train_data, val_data = all_data.iloc[train_index].copy(), all_data.iloc[val_index].copy()\n",
    "        target_mean = train_data.groupby(col).target.mean()\n",
    "        val_data[col + '_enc'] = val_data[col].map(target_mean)\n",
    "        all_data.iloc[val_index] = val_data\n",
    "\n",
    "    all_data[col + '_enc'].fillna(0.3343, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f181d9",
   "metadata": {},
   "source": [
    "Drop the non-encoded categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a331753",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.drop(index_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0c07e3",
   "metadata": {},
   "source": [
    "# Display the resulting dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "970bad6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>revenue_item_normalized_lag_1</th>\n",
       "      <th>revenue_normalized_lag_1</th>\n",
       "      <th>revenue_shop_normalized_lag_1</th>\n",
       "      <th>target_item_normalized_lag_1</th>\n",
       "      <th>target_normalized_lag_1</th>\n",
       "      <th>target_shop_normalized_lag_1</th>\n",
       "      <th>revenue_item_normalized_lag_2</th>\n",
       "      <th>revenue_normalized_lag_2</th>\n",
       "      <th>revenue_shop_normalized_lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>revenue_item_normalized_lag_12</th>\n",
       "      <th>revenue_normalized_lag_12</th>\n",
       "      <th>revenue_shop_normalized_lag_12</th>\n",
       "      <th>target_item_normalized_lag_12</th>\n",
       "      <th>target_normalized_lag_12</th>\n",
       "      <th>target_shop_normalized_lag_12</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>shop_id_enc</th>\n",
       "      <th>item_id_enc</th>\n",
       "      <th>item_category_id_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>0.005721</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.616214</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.401628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.828419</td>\n",
       "      <td>0.074755</td>\n",
       "      <td>0.162759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001921</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.003657</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.616214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>0.828419</td>\n",
       "      <td>0.098630</td>\n",
       "      <td>0.169217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>0.006695</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.031084</td>\n",
       "      <td>0.018901</td>\n",
       "      <td>0.616214</td>\n",
       "      <td>0.012128</td>\n",
       "      <td>0.012904</td>\n",
       "      <td>0.401628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40</td>\n",
       "      <td>0.828419</td>\n",
       "      <td>1.431898</td>\n",
       "      <td>0.241341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.006042</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>0.616214</td>\n",
       "      <td>0.006435</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.401628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "      <td>0.828419</td>\n",
       "      <td>0.213953</td>\n",
       "      <td>0.162759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.009670</td>\n",
       "      <td>0.616214</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.401628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57</td>\n",
       "      <td>0.828419</td>\n",
       "      <td>0.062338</td>\n",
       "      <td>0.092227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  revenue_item_normalized_lag_1  revenue_normalized_lag_1  \\\n",
       "0     4.0                       0.001766                  0.005721   \n",
       "1     3.0                       0.001921                  0.005365   \n",
       "2    14.0                       0.004218                  0.006695   \n",
       "3     3.0                       0.001887                  0.005476   \n",
       "4     1.0                       0.001119                  0.005365   \n",
       "\n",
       "   revenue_shop_normalized_lag_1  target_item_normalized_lag_1  \\\n",
       "0                       0.622419                      0.005088   \n",
       "1                       0.622419                      0.003657   \n",
       "2                       0.622419                      0.031084   \n",
       "3                       0.622419                      0.006042   \n",
       "4                       0.622419                      0.002067   \n",
       "\n",
       "   target_normalized_lag_1  target_shop_normalized_lag_1  \\\n",
       "0                 0.010989                      0.616214   \n",
       "1                 0.009670                      0.616214   \n",
       "2                 0.018901                      0.616214   \n",
       "3                 0.010110                      0.616214   \n",
       "4                 0.009670                      0.616214   \n",
       "\n",
       "   revenue_item_normalized_lag_2  revenue_normalized_lag_2  \\\n",
       "0                       0.001128                  0.005365   \n",
       "1                       0.000000                  0.000000   \n",
       "2                       0.012128                  0.012904   \n",
       "3                       0.006435                  0.008794   \n",
       "4                       0.001115                  0.005365   \n",
       "\n",
       "   revenue_shop_normalized_lag_2  ...  revenue_item_normalized_lag_12  \\\n",
       "0                       0.401628  ...                             0.0   \n",
       "1                       0.000000  ...                             0.0   \n",
       "2                       0.401628  ...                             0.0   \n",
       "3                       0.401628  ...                             0.0   \n",
       "4                       0.401628  ...                             0.0   \n",
       "\n",
       "   revenue_normalized_lag_12  revenue_shop_normalized_lag_12  \\\n",
       "0                        0.0                             0.0   \n",
       "1                        0.0                             0.0   \n",
       "2                        0.0                             0.0   \n",
       "3                        0.0                             0.0   \n",
       "4                        0.0                             0.0   \n",
       "\n",
       "   target_item_normalized_lag_12  target_normalized_lag_12  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "\n",
       "   target_shop_normalized_lag_12  item_category_id  shop_id_enc  item_id_enc  \\\n",
       "0                            0.0                37     0.828419     0.074755   \n",
       "1                            0.0                38     0.828419     0.098630   \n",
       "2                            0.0                40     0.828419     1.431898   \n",
       "3                            0.0                37     0.828419     0.213953   \n",
       "4                            0.0                57     0.828419     0.062338   \n",
       "\n",
       "   item_category_id_enc  \n",
       "0              0.162759  \n",
       "1              0.169217  \n",
       "2              0.241341  \n",
       "3              0.162759  \n",
       "4              0.092227  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2470caf",
   "metadata": {},
   "source": [
    "# Fit models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b929de1",
   "metadata": {},
   "source": [
    "## Gradient boosted decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc847023",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [col for col in all_data.columns if col != 'target']\n",
    "\n",
    "# Clip target values into the [0, 20] range, as in the test set\n",
    "label = all_data['target'].clip(lower=0, upper=20)\n",
    "\n",
    "xgtrain = xgb.DMatrix(all_data[x_cols], label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4146d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:1.06067\n",
      "[1]\ttrain-rmse:0.98056\n",
      "[2]\ttrain-rmse:0.93547\n",
      "[3]\ttrain-rmse:0.90794\n",
      "[4]\ttrain-rmse:0.89118\n",
      "[5]\ttrain-rmse:0.88024\n",
      "[6]\ttrain-rmse:0.87316\n",
      "[7]\ttrain-rmse:0.86750\n",
      "[8]\ttrain-rmse:0.86383\n",
      "[9]\ttrain-rmse:0.86089\n"
     ]
    }
   ],
   "source": [
    "param = {}\n",
    "num_round = 10\n",
    "evallist = [(xgtrain, 'train')]\n",
    "\n",
    "bst = xgb.train(param, xgtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86fc488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
